<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>TSEnsemble.utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TSEnsemble.utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose, STL
from statsmodels.tsa.arima.model import ARIMAResultsWrapper, ARIMA, ARIMAResults
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.graphics.tsaplots import plot_acf as statsmodel_plot_acf
import re

def ts_from_csv(dataset_path, column = 1, index = 0):
    &#34;&#34;&#34;
    Converts .csv file to pandas DataFrame, dropping all columns besides index and column.
    Args:
        dataset_path (str): path to .csv file.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
    Returns:
        DataFrame.
    &#34;&#34;&#34;
    if isinstance(column, int) or isinstance(column, str):
        df = pd.read_csv(dataset_path, parse_dates = True, index_col = index, usecols = [index, column])
    else:
        df = pd.read_csv(dataset_path, parse_dates = True, index_col = index, usecols = [index, *column])
    df.astype(float)
    df = df.interpolate()
    return df

def get_arima_model_S(model):
    &#34;&#34;&#34;
    Gets seasonality of arima model
    Args:
        model (obj): ARIMA model.
    Returns:
        int: season value
    &#34;&#34;&#34;
    if isinstance(model, ARIMA):
        return model.seasonal_order[3]

    summary_string = str(model.summary())
    param = re.findall(&#39;\(x\(([0-9]+), ([0-9]+), ([0-9]+), ([0-9]+)&#39;,summary_string)

    if param == []:
        return 0
    return int(param[0][3])

def get_arima_model_order(model):
    &#34;&#34;&#34;
    Gets order of arima model
    Args:
        model (obj): ARIMA model.
    Returns:
        (int, int, int) : p, d, q values
    &#34;&#34;&#34;
    if isinstance(model, ARIMA):
        return [int(x) for x in model.order]

    summary_string = str(model.summary())
    param = re.findall(&#39;ARIMA\([^)]*\)&#39;,summary_string)
    param = eval(param[0][5:].replace(&#39;[]&#39;, &#39;0&#39;))
    if param == []:
        return 0
    return [int(x) for x in param]

def get_arima_model_seasonal_order(model):
    &#34;&#34;&#34;
    Gets seasonal order of arima model
    Args:
        model (obj): ARIMA model.
    Returns:
        (int, int, int, int) : P, D, Q, S values
    &#34;&#34;&#34;
    if isinstance(model, ARIMA):
        return [int(x) for x in model.seasonal_order]

    summary_string = str(model.summary())
    param = re.findall(&#39;x\([^)]*\)&#39;,summary_string)
    param[0] = eval(param[0][1:].replace(&#34;[]&#34;, &#34;0&#34;))
    if param == []:
        return 0
    return [int(x) for x in param[0]]
    

def get_seasonality(model):
    &#34;&#34;&#34;
    Gets seasonality of created model
    Args:
        model (obj): ARIMA or keras model.
    Returns:
        (int) : season value
    &#34;&#34;&#34;
    if hasattr(model, &#39;input_shape&#39;):
        return model.input_shape[1]
    if isinstance(model, ARIMAResultsWrapper) or isinstance(model, ARIMA) or isinstance(model, ARIMAResults): # for ARIMA model
        return get_arima_model_S(model)

def get_coeff_determination(predictions, test):
    &#34;&#34;&#34;
    Gets the determination coefficient by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : Determination coefficient value. 
    &#34;&#34;&#34;
    res =  np.sum(np.square(test - predictions ))
    tot = np.sum(np.square(test - np.mean(test)))
    return (1 - res/(tot + np.epsilon()))

def get_rmse(predictions, test):
    &#34;&#34;&#34;
    Gets the RMSE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : RMSE value. 
    &#34;&#34;&#34;
    return np.sqrt(((np.asanyarray(test) - np.asanyarray(predictions)) ** 2).mean())

def get_mse(predictions, test):
    &#34;&#34;&#34;
    Gets the MSE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : MSE value. 
    &#34;&#34;&#34;
    return ((np.asanyarray(test) - np.asanyarray(predictions)) ** 2).mean()

def get_mae(predictions, test):
    &#34;&#34;&#34;
    Gets the MAE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : MAE value. 
    &#34;&#34;&#34;
    return np.abs(np.asanyarray(test) - np.asanyarray(predictions)).mean()

def get_mape(predictions, test):
    &#34;&#34;&#34;
    Gets the MAPE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : MAPE value. 
    &#34;&#34;&#34;
    return np.abs((np.asanyarray(test) - np.asanyarray(predictions))/np.asanyarray(test)).mean()

def create_dataset(dataset, look_back = 0):
    &#34;&#34;&#34;
    Converts an array of values into a dataset matrix.
    Args:
        dataset (DataFrame, ndarray): dataset to use.
        look_back (int): amount of values in a single X.
    Returns:
        (ndarray), (ndarray) : X, y
    &#34;&#34;&#34;
    dataX, dataY = [], []

    if look_back == 0:
        look_back = 1

    for i in range(len(dataset) - look_back):
        a = dataset[i:(i + look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

def plot_decompose(dataset_path, period = None, column = 1, index = 0, max_plot = 10000, model = &#34;additive&#34;, method = &#34;stl&#34;, seasonal = 7, trend = None):
    &#34;&#34;&#34;
    Take path of dataset and plot a decompose on trend and seasonality
    
    Args:
        dataset_path (str): path to .csv file.
        period (int, None): period of the series.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
        max_plot(int): maximum number of values to plot.
        model (&#34;additive&#34;, &#34;multiplicative&#34;): seasonal decompose model.
        method (&#34;stl&#34;, &#34;ma&#34;, &#34;naive&#34;, &#34;seasonal_decompose&#34;): method of decomposition. &#34;ma&#34; and &#34;naive&#34; refer to seasonal_decompose
        seasonal (int): required for Seasonal ARIMA. Seasonality of time series.
        trend (int, None): length of the trend smoother.
    &#34;&#34;&#34;
    dataset = pd.read_csv(dataset_path, parse_dates=True, index_col=index, usecols = [index, column])
    dataset = dataset.interpolate()
    if method.lower() == &#34;stl&#34;:
        result = STL(dataset[-max_plot:].squeeze(), period = period, seasonal = seasonal, trend = trend).fit()
    elif method is None or method.lower() == &#34;ma&#34; or method.lower() == &#34;naive&#34; or method.lower() == &#34;seasonal_decompose&#34;:
        result = seasonal_decompose(dataset[-max_plot:], model=model, period=period)
    else:
        raise Exception(&#34;method cant be identified&#34;)
    
    result.plot()
    plt.show()

def plot_acf(dataset_path, lags = 12, column = 1, index = 0):
    &#34;&#34;&#34;
    Take path of dataset and plot a decompose on trend and seasonality
    
    Args:
        dataset_path (str): path to .csv file.
        lags (int): amount of lags to plot.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
    &#34;&#34;&#34;
    dataset = pd.read_csv(dataset_path, parse_dates=True, index_col=index, usecols = [index, column])
    dataset = dataset.interpolate()
    statsmodel_plot_acf(dataset, lags = lags)

def isStationary(dataset_path, window = None, column = 1, index = 0, alpha = 0.05, plot = True, fig_size = (15, 5), verbose = True, test = &#34;both&#34;):
    &#34;&#34;&#34;
    Take path of dataset and make a conclusion on stationarity by using Dickey-Fuller Test
    
    Args:
        dataset_path (str): path to .csv file.
        window (int, None): window for means and stddevs calculation.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
        alpha (float): alpha value. Recommended values: 0.05, 0.01, 0.1.
        plot (bool): print a plot.
        fig_size ((int, int)): size of a plot.
        verbose(int): print additional information.
        test (&#34;both&#34;, &#34;kpss&#34;, &#34;adf&#34;): tests to use. Default: &#34;both&#34;
        
    Returns:
        (bool) : test result.
    &#34;&#34;&#34;

    # Read data to DataFrame
    ts = pd.read_csv(dataset_path, parse_dates=True, index_col=index, usecols = [index, column])
    # Interpolate missing values
    ts = ts.interpolate()

    # Automatically choose a window for plot
    if window is None:
        window = round(ts.shape[0]/50)

    ts = ts.squeeze()

    if plot:
        # Plot rolling means and variances
        pd.DataFrame({&#39;Actual&#39;: ts,
                    &#39;Means&#39;: ts.rolling(window=window).mean(),
                    &#39;Stddevs&#39;: ts.rolling(window=window).std()
                    }, index=ts.index).plot(figsize = fig_size)

    # Run the tests
    if test.lower() == &#34;both&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            result2 = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;ADF test: \n&#34;, result)
            print(&#34;KPSS test: &#34;, result2)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha and test_kpss[1] &gt; alpha: 
            return True
        else:
            return False
        
    # Run the tests
    elif test.lower() == &#34;adf&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            print(&#34;ADF test: \n&#34;, result)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha: 
            return True
        else:
            return False

    # Run the tests
    elif test.lower() == &#34;kpss&#34;:
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;KPSS test: &#34;, result)

        # if p-value is less than alpha  return True
        if test_kpss[1] &gt; alpha: 
            return True
        else:
            return False
        

    
def isStationaryArray(ts, window = None, alpha = 0.05, plot = True, fig_size = (15, 5), verbose = True, test = &#34;both&#34;):
    &#34;&#34;&#34;
    Take numpy array and make a conclusion on stationarity by using Dickey-Fuller Test
    
    Args:
        ts (ndarray): time series.
        window (int, None): window for means and stddevs calculation.
        alpha (float): alpha value. Recommended values: 0.05, 0.01, 0.1.
        plot (bool): print a plot.
        fig_size ((int, int)): size of a plot.
        verbose(int): print additional information.
        test (&#34;both&#34;, &#34;kpss&#34;, &#34;adf&#34;): tests to use. Default: &#34;both&#34;
        
    Returns:
        (bool) : test result.
    &#34;&#34;&#34;

    if not(isinstance(ts, np.ndarray)):
        if hasattr(ts, &#39;values&#39;):
            ts = ts.values
        ts = np.array(ts)
        ts = ts.astype(&#39;float64&#39;)

    ts = pd.DataFrame(ts)
    ts = ts.interpolate()
    ts = ts.squeeze()

    window = round(ts.shape[0]/95)

    if plot:
        # Plot rolling means and variances
        pd.DataFrame({&#39;Actual&#39;: ts,
                    &#39;Means&#39;: ts.rolling(window=window).mean(),
                    &#39;Stddevs&#39;: ts.rolling(window=window).std()
                    }, index=ts.index).plot(figsize = fig_size)

    # Run the tests
    if test.lower() == &#34;both&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            result2 = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;ADF test: \n&#34;, result)
            print(&#34;KPSS test: &#34;, result2)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha and test_kpss[1] &gt; alpha: 
            return True
        else:
            return False
        
    # Run the tests
    elif test.lower() == &#34;adf&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            print(&#34;ADF test: \n&#34;, result)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha: 
            return True
        else:
            return False

    # Run the tests
    elif test.lower() == &#34;kpss&#34;:
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;KPSS test: &#34;, result)

        # if p-value is less than alpha  return True
        if test_kpss[1] &gt; alpha: 
            return True
        else:
            return False

def interpolate_nan(array_like):
    &#34;&#34;&#34;
    Take numpy array and fill all NaNs using interpolation method.
    
    Args:
        array_like (DataFrame, ndarray): dataset.
        
    Returns:
        (ndarray) : interpolated dataset
    &#34;&#34;&#34;
    array = array_like.copy()

    nans = np.isnan(array)

    def get_x(a):
        return a.nonzero()[0]

    array[nans] = np.interp(get_x(nans), get_x(~nans), array[~nans])

    return array


def prepare_dataset(dataset, train_size = None, test_size = None, look_back = 12, val_size = None, n_features = 1):
    &#34;&#34;&#34;
    Split dataset on training, validation and testing arrays, scale data.
    
    Args:
        dataset (DataFrame, ndarray): time series dataset.
        train_size (float): Value from 0 to 1 to specify fraction of train dataset. Default value : 0.9.
        test_size (float): Value from 0 to 1 to specify fraction of test dataset. Not needed if train_size is specified. Default value : 1 - train_size
        look_back (int): amount of values in a single X.
        val_size (float): Value from 0 to 1 to specify fraction of val dataset inside of a train dataset. Default value : 0.1.
        n_features (int): dimensions of time series. Multivariate time series not fully supported.
        
    Returns:train_x_stf, train_y, val_x_stf, val_y, test_x_stf, test_y, trainScaler, valScaler, testScaler
        (ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, obj, obj, obj) : train X, train y, val X, val y, test X, test y, trainScaler object, valScaler object, testScaler object.
    &#34;&#34;&#34;
    if not(isinstance(dataset, np.ndarray)):
        dataset = dataset.values
        dataset = dataset.astype(&#39;float64&#39;)

    if (np.isnan(dataset).any()):
        dataset = interpolate_nan(dataset)

    if train_size is None: 
        if test_size is None:
            train_size = 0.9
        elif test_size &lt; 1:
            train_size = 1 - test_size
        else:
            train_size = test_size/len(dataset)

    if val_size is None:
        val_size = (train_size)/10
    else:
        val_size = (train_size * val_size)

    # split into train and test sets
    train_size = train_size - val_size
    train_num = int(len(dataset) * train_size)
    val_num = train_num + int(len(dataset) * val_size)
    train, val, test = dataset[:train_num, :], dataset[train_num:val_num, :], dataset[val_num:, :]

    # normalize dataset separately
    trainScaler = MinMaxScaler(feature_range=(-1, 1))
    train = trainScaler.fit_transform(train)

    valScaler = MinMaxScaler(feature_range=(-1, 1))
    val = valScaler.fit_transform(val)

    testScaler = MinMaxScaler(feature_range=(-1, 1))
    test = testScaler.fit_transform(test)   

    # reshape into X=t and Y=t+1
    scaled_dataset = np.array(train.tolist() + val.tolist() + test.tolist())
    scaled_x, scaled_y = create_dataset(scaled_dataset, look_back)
    train_x = scaled_x[:train_num - look_back]
    train_y = scaled_y[:train_num - look_back]
    val_x = scaled_x[train_num - look_back:val_num - look_back]
    val_y = scaled_y[train_num - look_back:val_num - look_back]
    test_x = scaled_x[val_num - look_back:]
    test_y = scaled_y[val_num - look_back:]

    # reshape input to be [samples, time steps, features]
    train_x_stf = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], n_features))
    test_x_stf = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], n_features))
    val_x_stf = np.reshape(val_x, (val_x.shape[0], val_x.shape[1], n_features))

    return train_x_stf, train_y, val_x_stf, val_y, test_x_stf, test_y, trainScaler, valScaler, testScaler

def predict_array(model, 
                  dataset, 
                  look_back, 
                  scaler = None, 
                  plot = True, 
                  get = &#34;mape&#34;, 
                  print_values = True, 
                  verbose = True, 
                  fig_size = (15, 5)):
    &#34;&#34;&#34;
    Show fitted model predictions on a given data
    
    Args:
        model (obj): model used for predictions.
        dataset (DataFrame, ndarray): time series dataset.
        look_back (int): amount of values in a single X.
        scaler (obj): scaler object.
        plot (bool): plot predictions.
        get (str): error metric to return. Supports rmse, mse, mae, mape, all.
        print_values (bool): prints predictions and actuals DataFrame.
        verbose(int): print additional information.
        fig_size ((int, int)): size of a plot.
    Returns:
        (float, dict of floats) : error metric.
    &#34;&#34;&#34;
    # if look_back is None:
    #     print(&#34;Look_back not set, setting to 12...&#34;)
    #     look_back = 12

    if scaler is None:
        scaler = MinMaxScaler(feature_range=(-1, 1))
        data = Scaler.fit_transform(dataset)

    # extract X and y values from data
    data_x, data_y = create_dataset(data, look_back)
    x_stf = np.reshape(data_x, (data_x.shape[0], data_x.shape[1], 1))

    return eval_model(model, 
                    x_stf, 
                    data_y, 
                    scaler, 
                    max_plot = 100, 
                    plot = plot, 
                    get = get, 
                    print_values = print_values, 
                    verbose = verbose, 
                    fig_size = fig_size)

def model_forecast(model, dataset, n = 1, plot = True, fig_size = (15, 5), datePlot = &#34;date&#34;, dateStep = 1, n_features = 1):
    &#34;&#34;&#34;
    Out-of-sample forecast of a fitted model, based on a given dataset.
    Plots Predictions, Actuals (with data, if index is datetime64).

    Args:
        model (obj): model used for predictions.
        dataset (DataFrame, ndarray): time series dataset.
        n (int): amount of values to predict.
        fig_size ((int, int)): size of a plot.
        datePlot (&#34;date&#34;, &#34;time&#34;): format of date. Date example : 09.01.2024, time example: 21:10
        dateStep (int): prints each n date. 
        n_features (int): dimensions of time series. Multivariate time series not fully supported.
    Returns:
        (DataFrame) : predictions and actuals DataFrame.
    &#34;&#34;&#34;   
    if isinstance(dataset, str):
        dataset = ts_from_csv(dataset)

    # Create date indices for predictions
    if isinstance(dataset, pd.DataFrame) and dataset.index.inferred_type == &#39;datetime64&#39;:
        if dataset.index.inferred_type == &#39;datetime64&#39;:
            last_date = dataset.index[-1]
            delta = last_date - dataset.index[-2]
            if delta.days &gt;= 28 and delta.days &lt;=31:
                delta = pd.DateOffset(months=1)
            offset = pd.tseries.frequencies.to_offset(delta)
            dateIndex = pd.date_range(last_date + delta, last_date + delta*n, freq=offset)

    dataset = np.array(dataset)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    dataset = scaler.fit_transform(dataset)
    dataset = dataset.tolist()
    s = get_seasonality(model)
    if isinstance(model, ARIMA) or isinstance(model, ARIMAResultsWrapper)  or isinstance(model, ARIMAResults): 
        model = ARIMA(scaler.inverse_transform(dataset), 
                    order = get_arima_model_order(model), 
                    seasonal_order = get_arima_model_seasonal_order(model))
        model = model.fit()
        predictions = model.forecast(n).reshape((-1, 1))
    else:
    # Generate n predictions, use last look_back values
        X = dataset[-s:]
        predictions = []
        for i in range(n):
            fromX = s - i
            a = X[-fromX:] if fromX &gt; 0 else []
            fromPredictions = min(i,s)
            a = a + predictions[-fromPredictions:]
            a = np.array(a).reshape(1, -1, n_features)
            prediction = model.predict(a, verbose = 0).tolist()
            predictions = predictions + prediction

        predictions = scaler.inverse_transform(predictions)
    
    df = pd.DataFrame({&#39;predictions&#39;: predictions.flatten()}, index = dateIndex)
    if plot:
        # Get indices for plotting
        if datePlot == &#34;date&#34;:
            date = [str(d)[:10] for d in df.index.values]
        elif datePlot == &#34;time&#34;: 
            date = [str(d)[11:16] for d in df.index.values]
        
        x = date
        y = df[&#34;predictions&#34;].values.tolist()

        # plot predictions
        plt.figure(figsize=fig_size)
        plt.plot(x,y)
        plt.xticks(rotation = 75)
        plt.xticks(np.arange(0, len(x)+1, dateStep))
        plt.show()

    return df

def eval_model(model, test_x, test_y, testScaler = None, get = &#34;mape&#34;, plot = True, max_plot = 100, print_values = True, verbose = True, fig_size = (15, 5)):
    &#34;&#34;&#34;
    Use model to forecast values based on test X and y, if data is scaled it requires a Scaler.
    Returns single chosen error metric from RMSE MSE MAE MAPE. Use &#34;all&#34; for a dictionary. 
    If verbose = True, prints all errors.
    If plot = True plots Predictions, Actual plot.
    If print_values = True, prints Predictions, Actual DataFrame.
    
    Args:
        model (obj): model used for predictions.
        test_x (ndarray): test X values.
        test_y (ndarray): test y values.
        testScaler (obj): scaler object.
        get (str): error metric to return. Supports rmse, mse, mae, mape, all.
        plot (bool): plot predictions.
        max_plot(int): maximum number of values to plot.
        print_values (bool): prints predictions and actuals DataFrame.
        verbose(int): print additional information.
        fig_size ((int, int)): size of a plot.
    Returns:
        (float, dict of floats) : error metric.
    &#34;&#34;&#34;   

    predictions = model.predict(test_x).flatten()
    if not(testScaler is None):
        [predictions, test_y] = testScaler.inverse_transform([predictions, test_y])

    if plot:
            plt.figure(figsize=fig_size)
            if max_plot&lt;len(test_y):
                plt.plot(test_y[-max_plot:], label = &#34;Actual&#34;)
                plt.plot(predictions[-max_plot:], label = &#34;Prediction&#34;)
            else:
                plt.plot(test_y, label = &#34;Actual&#34;)
                plt.plot(predictions, label = &#34;Prediction&#34;)               
            plt.ylabel(&#39;Values&#39;, fontsize=15)
            plt.legend()
            plt.show()

    if print_values:
        predicts = pd.DataFrame({&#39;prediction&#39; : predictions, &#39;actual&#39; : test_y})
        print(predicts)

    if verbose == False:
        return pd.DataFrame({&#39;prediction&#39; : predictions, &#39;actual&#39; : test_y})

    # get metrics
    rmse = get_rmse(predictions, test_y)
    mse = get_mse(predictions, test_y)
    mae = get_mae(predictions, test_y)
    mape = get_mape(predictions, test_y)
    print(&#34;RMSE = {}, MSE = {}, MAE = {}, MAPE = {}&#34;.format(rmse, mse, mae, mape))

    if get == &#34;rmse&#34; or get == &#34;RMSE&#34;:
        return rmse
    if get == &#34;mse&#34; or get == &#34;MSE&#34;:
        return mse
    if get == &#34;mae&#34; or get == &#34;MAE&#34;:
        return mae
    if get == &#34;mape&#34; or get == &#34;MAPE&#34;:
        return mape
    if get == &#34;all&#34; or get == &#34;ALL&#34;:
        return {&#39;RMSE&#39; : rmse, &#39;MSE&#39; : mse, &#39;MAE&#39; : mae, &#39;MAPE&#39; : mape}
    return </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="TSEnsemble.utils.create_dataset"><code class="name flex">
<span>def <span class="ident">create_dataset</span></span>(<span>dataset, look_back=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts an array of values into a dataset matrix.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>DataFrame, ndarray</code></dt>
<dd>dataset to use.</dd>
<dt><strong><code>look_back</code></strong> :&ensp;<code>int</code></dt>
<dd>amount of values in a single X.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(ndarray), (ndarray) : X, y</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_dataset(dataset, look_back = 0):
    &#34;&#34;&#34;
    Converts an array of values into a dataset matrix.
    Args:
        dataset (DataFrame, ndarray): dataset to use.
        look_back (int): amount of values in a single X.
    Returns:
        (ndarray), (ndarray) : X, y
    &#34;&#34;&#34;
    dataX, dataY = [], []

    if look_back == 0:
        look_back = 1

    for i in range(len(dataset) - look_back):
        a = dataset[i:(i + look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.eval_model"><code class="name flex">
<span>def <span class="ident">eval_model</span></span>(<span>model, test_x, test_y, testScaler=None, get='mape', plot=True, max_plot=100, print_values=True, verbose=True, fig_size=(15, 5))</span>
</code></dt>
<dd>
<div class="desc"><p>Use model to forecast values based on test X and y, if data is scaled it requires a Scaler.
Returns single chosen error metric from RMSE MSE MAE MAPE. Use "all" for a dictionary.
If verbose = True, prints all errors.
If plot = True plots Predictions, Actual plot.
If print_values = True, prints Predictions, Actual DataFrame.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>model used for predictions.</dd>
<dt><strong><code>test_x</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>test X values.</dd>
<dt><strong><code>test_y</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>test y values.</dd>
<dt><strong><code>testScaler</code></strong> :&ensp;<code>obj</code></dt>
<dd>scaler object.</dd>
<dt><strong><code>get</code></strong> :&ensp;<code>str</code></dt>
<dd>error metric to return. Supports rmse, mse, mae, mape, all.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>plot predictions.</dd>
<dt>max_plot(int): maximum number of values to plot.</dt>
<dt><strong><code>print_values</code></strong> :&ensp;<code>bool</code></dt>
<dd>prints predictions and actuals DataFrame.</dd>
</dl>
<p>verbose(int): print additional information.
fig_size ((int, int)): size of a plot.</p>
<h2 id="returns">Returns</h2>
<p>(float, dict of floats) : error metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_model(model, test_x, test_y, testScaler = None, get = &#34;mape&#34;, plot = True, max_plot = 100, print_values = True, verbose = True, fig_size = (15, 5)):
    &#34;&#34;&#34;
    Use model to forecast values based on test X and y, if data is scaled it requires a Scaler.
    Returns single chosen error metric from RMSE MSE MAE MAPE. Use &#34;all&#34; for a dictionary. 
    If verbose = True, prints all errors.
    If plot = True plots Predictions, Actual plot.
    If print_values = True, prints Predictions, Actual DataFrame.
    
    Args:
        model (obj): model used for predictions.
        test_x (ndarray): test X values.
        test_y (ndarray): test y values.
        testScaler (obj): scaler object.
        get (str): error metric to return. Supports rmse, mse, mae, mape, all.
        plot (bool): plot predictions.
        max_plot(int): maximum number of values to plot.
        print_values (bool): prints predictions and actuals DataFrame.
        verbose(int): print additional information.
        fig_size ((int, int)): size of a plot.
    Returns:
        (float, dict of floats) : error metric.
    &#34;&#34;&#34;   

    predictions = model.predict(test_x).flatten()
    if not(testScaler is None):
        [predictions, test_y] = testScaler.inverse_transform([predictions, test_y])

    if plot:
            plt.figure(figsize=fig_size)
            if max_plot&lt;len(test_y):
                plt.plot(test_y[-max_plot:], label = &#34;Actual&#34;)
                plt.plot(predictions[-max_plot:], label = &#34;Prediction&#34;)
            else:
                plt.plot(test_y, label = &#34;Actual&#34;)
                plt.plot(predictions, label = &#34;Prediction&#34;)               
            plt.ylabel(&#39;Values&#39;, fontsize=15)
            plt.legend()
            plt.show()

    if print_values:
        predicts = pd.DataFrame({&#39;prediction&#39; : predictions, &#39;actual&#39; : test_y})
        print(predicts)

    if verbose == False:
        return pd.DataFrame({&#39;prediction&#39; : predictions, &#39;actual&#39; : test_y})

    # get metrics
    rmse = get_rmse(predictions, test_y)
    mse = get_mse(predictions, test_y)
    mae = get_mae(predictions, test_y)
    mape = get_mape(predictions, test_y)
    print(&#34;RMSE = {}, MSE = {}, MAE = {}, MAPE = {}&#34;.format(rmse, mse, mae, mape))

    if get == &#34;rmse&#34; or get == &#34;RMSE&#34;:
        return rmse
    if get == &#34;mse&#34; or get == &#34;MSE&#34;:
        return mse
    if get == &#34;mae&#34; or get == &#34;MAE&#34;:
        return mae
    if get == &#34;mape&#34; or get == &#34;MAPE&#34;:
        return mape
    if get == &#34;all&#34; or get == &#34;ALL&#34;:
        return {&#39;RMSE&#39; : rmse, &#39;MSE&#39; : mse, &#39;MAE&#39; : mae, &#39;MAPE&#39; : mape}
    return </code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_arima_model_S"><code class="name flex">
<span>def <span class="ident">get_arima_model_S</span></span>(<span>model)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets seasonality of arima model</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>ARIMA model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>season value</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_arima_model_S(model):
    &#34;&#34;&#34;
    Gets seasonality of arima model
    Args:
        model (obj): ARIMA model.
    Returns:
        int: season value
    &#34;&#34;&#34;
    if isinstance(model, ARIMA):
        return model.seasonal_order[3]

    summary_string = str(model.summary())
    param = re.findall(&#39;\(x\(([0-9]+), ([0-9]+), ([0-9]+), ([0-9]+)&#39;,summary_string)

    if param == []:
        return 0
    return int(param[0][3])</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_arima_model_order"><code class="name flex">
<span>def <span class="ident">get_arima_model_order</span></span>(<span>model)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets order of arima model</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>ARIMA model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(int, int, int) : p, d, q values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_arima_model_order(model):
    &#34;&#34;&#34;
    Gets order of arima model
    Args:
        model (obj): ARIMA model.
    Returns:
        (int, int, int) : p, d, q values
    &#34;&#34;&#34;
    if isinstance(model, ARIMA):
        return [int(x) for x in model.order]

    summary_string = str(model.summary())
    param = re.findall(&#39;ARIMA\([^)]*\)&#39;,summary_string)
    param = eval(param[0][5:].replace(&#39;[]&#39;, &#39;0&#39;))
    if param == []:
        return 0
    return [int(x) for x in param]</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_arima_model_seasonal_order"><code class="name flex">
<span>def <span class="ident">get_arima_model_seasonal_order</span></span>(<span>model)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets seasonal order of arima model</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>ARIMA model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(int, int, int, int) : P, D, Q, S values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_arima_model_seasonal_order(model):
    &#34;&#34;&#34;
    Gets seasonal order of arima model
    Args:
        model (obj): ARIMA model.
    Returns:
        (int, int, int, int) : P, D, Q, S values
    &#34;&#34;&#34;
    if isinstance(model, ARIMA):
        return [int(x) for x in model.seasonal_order]

    summary_string = str(model.summary())
    param = re.findall(&#39;x\([^)]*\)&#39;,summary_string)
    param[0] = eval(param[0][1:].replace(&#34;[]&#34;, &#34;0&#34;))
    if param == []:
        return 0
    return [int(x) for x in param[0]]</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_coeff_determination"><code class="name flex">
<span>def <span class="ident">get_coeff_determination</span></span>(<span>predictions, test)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the determination coefficient by comparing the test data and predictions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>predictions</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>prediction values.</dd>
<dt><strong><code>test</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>observed values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(float) : Determination coefficient value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_coeff_determination(predictions, test):
    &#34;&#34;&#34;
    Gets the determination coefficient by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : Determination coefficient value. 
    &#34;&#34;&#34;
    res =  np.sum(np.square(test - predictions ))
    tot = np.sum(np.square(test - np.mean(test)))
    return (1 - res/(tot + np.epsilon()))</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_mae"><code class="name flex">
<span>def <span class="ident">get_mae</span></span>(<span>predictions, test)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the MAE by comparing the test data and predictions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>predictions</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>prediction values.</dd>
<dt><strong><code>test</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>observed values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(float) : MAE value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mae(predictions, test):
    &#34;&#34;&#34;
    Gets the MAE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : MAE value. 
    &#34;&#34;&#34;
    return np.abs(np.asanyarray(test) - np.asanyarray(predictions)).mean()</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_mape"><code class="name flex">
<span>def <span class="ident">get_mape</span></span>(<span>predictions, test)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the MAPE by comparing the test data and predictions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>predictions</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>prediction values.</dd>
<dt><strong><code>test</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>observed values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(float) : MAPE value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mape(predictions, test):
    &#34;&#34;&#34;
    Gets the MAPE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : MAPE value. 
    &#34;&#34;&#34;
    return np.abs((np.asanyarray(test) - np.asanyarray(predictions))/np.asanyarray(test)).mean()</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_mse"><code class="name flex">
<span>def <span class="ident">get_mse</span></span>(<span>predictions, test)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the MSE by comparing the test data and predictions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>predictions</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>prediction values.</dd>
<dt><strong><code>test</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>observed values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(float) : MSE value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mse(predictions, test):
    &#34;&#34;&#34;
    Gets the MSE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : MSE value. 
    &#34;&#34;&#34;
    return ((np.asanyarray(test) - np.asanyarray(predictions)) ** 2).mean()</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_rmse"><code class="name flex">
<span>def <span class="ident">get_rmse</span></span>(<span>predictions, test)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the RMSE by comparing the test data and predictions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>predictions</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>prediction values.</dd>
<dt><strong><code>test</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>observed values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(float) : RMSE value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_rmse(predictions, test):
    &#34;&#34;&#34;
    Gets the RMSE by comparing the test data and predictions
    Args:
        predictions (ndarray): prediction values.
        test (ndarray): observed values.
    Returns:
        (float) : RMSE value. 
    &#34;&#34;&#34;
    return np.sqrt(((np.asanyarray(test) - np.asanyarray(predictions)) ** 2).mean())</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.get_seasonality"><code class="name flex">
<span>def <span class="ident">get_seasonality</span></span>(<span>model)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets seasonality of created model</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>ARIMA or keras model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(int) : season value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_seasonality(model):
    &#34;&#34;&#34;
    Gets seasonality of created model
    Args:
        model (obj): ARIMA or keras model.
    Returns:
        (int) : season value
    &#34;&#34;&#34;
    if hasattr(model, &#39;input_shape&#39;):
        return model.input_shape[1]
    if isinstance(model, ARIMAResultsWrapper) or isinstance(model, ARIMA) or isinstance(model, ARIMAResults): # for ARIMA model
        return get_arima_model_S(model)</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.interpolate_nan"><code class="name flex">
<span>def <span class="ident">interpolate_nan</span></span>(<span>array_like)</span>
</code></dt>
<dd>
<div class="desc"><p>Take numpy array and fill all NaNs using interpolation method.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>array_like</code></strong> :&ensp;<code>DataFrame, ndarray</code></dt>
<dd>dataset.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(ndarray) : interpolated dataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolate_nan(array_like):
    &#34;&#34;&#34;
    Take numpy array and fill all NaNs using interpolation method.
    
    Args:
        array_like (DataFrame, ndarray): dataset.
        
    Returns:
        (ndarray) : interpolated dataset
    &#34;&#34;&#34;
    array = array_like.copy()

    nans = np.isnan(array)

    def get_x(a):
        return a.nonzero()[0]

    array[nans] = np.interp(get_x(nans), get_x(~nans), array[~nans])

    return array</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.isStationary"><code class="name flex">
<span>def <span class="ident">isStationary</span></span>(<span>dataset_path, window=None, column=1, index=0, alpha=0.05, plot=True, fig_size=(15, 5), verbose=True, test='both')</span>
</code></dt>
<dd>
<div class="desc"><p>Take path of dataset and make a conclusion on stationarity by using Dickey-Fuller Test</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to .csv file.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>int, None</code></dt>
<dd>window for means and stddevs calculation.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>int, str, iterable</code></dt>
<dd>column index or name of time series values. Multivariate time series not fully supported yet.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int, str</code></dt>
<dd>column index or name of time series timestamps.</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>alpha value. Recommended values: 0.05, 0.01, 0.1.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>print a plot.</dd>
</dl>
<p>fig_size ((int, int)): size of a plot.
verbose(int): print additional information.
test ("both", "kpss", "adf"): tests to use. Default: "both"</p>
<h2 id="returns">Returns</h2>
<p>(bool) : test result.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isStationary(dataset_path, window = None, column = 1, index = 0, alpha = 0.05, plot = True, fig_size = (15, 5), verbose = True, test = &#34;both&#34;):
    &#34;&#34;&#34;
    Take path of dataset and make a conclusion on stationarity by using Dickey-Fuller Test
    
    Args:
        dataset_path (str): path to .csv file.
        window (int, None): window for means and stddevs calculation.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
        alpha (float): alpha value. Recommended values: 0.05, 0.01, 0.1.
        plot (bool): print a plot.
        fig_size ((int, int)): size of a plot.
        verbose(int): print additional information.
        test (&#34;both&#34;, &#34;kpss&#34;, &#34;adf&#34;): tests to use. Default: &#34;both&#34;
        
    Returns:
        (bool) : test result.
    &#34;&#34;&#34;

    # Read data to DataFrame
    ts = pd.read_csv(dataset_path, parse_dates=True, index_col=index, usecols = [index, column])
    # Interpolate missing values
    ts = ts.interpolate()

    # Automatically choose a window for plot
    if window is None:
        window = round(ts.shape[0]/50)

    ts = ts.squeeze()

    if plot:
        # Plot rolling means and variances
        pd.DataFrame({&#39;Actual&#39;: ts,
                    &#39;Means&#39;: ts.rolling(window=window).mean(),
                    &#39;Stddevs&#39;: ts.rolling(window=window).std()
                    }, index=ts.index).plot(figsize = fig_size)

    # Run the tests
    if test.lower() == &#34;both&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            result2 = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;ADF test: \n&#34;, result)
            print(&#34;KPSS test: &#34;, result2)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha and test_kpss[1] &gt; alpha: 
            return True
        else:
            return False
        
    # Run the tests
    elif test.lower() == &#34;adf&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            print(&#34;ADF test: \n&#34;, result)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha: 
            return True
        else:
            return False

    # Run the tests
    elif test.lower() == &#34;kpss&#34;:
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;KPSS test: &#34;, result)

        # if p-value is less than alpha  return True
        if test_kpss[1] &gt; alpha: 
            return True
        else:
            return False</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.isStationaryArray"><code class="name flex">
<span>def <span class="ident">isStationaryArray</span></span>(<span>ts, window=None, alpha=0.05, plot=True, fig_size=(15, 5), verbose=True, test='both')</span>
</code></dt>
<dd>
<div class="desc"><p>Take numpy array and make a conclusion on stationarity by using Dickey-Fuller Test</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>time series.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>int, None</code></dt>
<dd>window for means and stddevs calculation.</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>alpha value. Recommended values: 0.05, 0.01, 0.1.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>print a plot.</dd>
</dl>
<p>fig_size ((int, int)): size of a plot.
verbose(int): print additional information.
test ("both", "kpss", "adf"): tests to use. Default: "both"</p>
<h2 id="returns">Returns</h2>
<p>(bool) : test result.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isStationaryArray(ts, window = None, alpha = 0.05, plot = True, fig_size = (15, 5), verbose = True, test = &#34;both&#34;):
    &#34;&#34;&#34;
    Take numpy array and make a conclusion on stationarity by using Dickey-Fuller Test
    
    Args:
        ts (ndarray): time series.
        window (int, None): window for means and stddevs calculation.
        alpha (float): alpha value. Recommended values: 0.05, 0.01, 0.1.
        plot (bool): print a plot.
        fig_size ((int, int)): size of a plot.
        verbose(int): print additional information.
        test (&#34;both&#34;, &#34;kpss&#34;, &#34;adf&#34;): tests to use. Default: &#34;both&#34;
        
    Returns:
        (bool) : test result.
    &#34;&#34;&#34;

    if not(isinstance(ts, np.ndarray)):
        if hasattr(ts, &#39;values&#39;):
            ts = ts.values
        ts = np.array(ts)
        ts = ts.astype(&#39;float64&#39;)

    ts = pd.DataFrame(ts)
    ts = ts.interpolate()
    ts = ts.squeeze()

    window = round(ts.shape[0]/95)

    if plot:
        # Plot rolling means and variances
        pd.DataFrame({&#39;Actual&#39;: ts,
                    &#39;Means&#39;: ts.rolling(window=window).mean(),
                    &#39;Stddevs&#39;: ts.rolling(window=window).std()
                    }, index=ts.index).plot(figsize = fig_size)

    # Run the tests
    if test.lower() == &#34;both&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            result2 = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;ADF test: \n&#34;, result)
            print(&#34;KPSS test: &#34;, result2)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha and test_kpss[1] &gt; alpha: 
            return True
        else:
            return False
        
    # Run the tests
    elif test.lower() == &#34;adf&#34;:
        test_df = adfuller(ts, autolag=&#39;AIC&#39;)
    
        if verbose:
            result = pd.concat([pd.Series(test_df[:4],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;, &#39;numobs&#39;]),
                                pd.Series(test_df[4])])
            print(&#34;ADF test: \n&#34;, result)

        # if p-value is less than alpha  return True
        if test_df[1] &lt; alpha: 
            return True
        else:
            return False

    # Run the tests
    elif test.lower() == &#34;kpss&#34;:
        test_kpss = kpss(ts)
    
        if verbose:
            result = pd.concat([pd.Series(test_kpss[:3],
                                    index=[&#39;stat&#39;, &#39;pval&#39;, &#39;lags&#39;]),
                                pd.Series(test_kpss[3])])
            print(&#34;KPSS test: &#34;, result)

        # if p-value is less than alpha  return True
        if test_kpss[1] &gt; alpha: 
            return True
        else:
            return False</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.model_forecast"><code class="name flex">
<span>def <span class="ident">model_forecast</span></span>(<span>model, dataset, n=1, plot=True, fig_size=(15, 5), datePlot='date', dateStep=1, n_features=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Out-of-sample forecast of a fitted model, based on a given dataset.
Plots Predictions, Actuals (with data, if index is datetime64).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>model used for predictions.</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>DataFrame, ndarray</code></dt>
<dd>time series dataset.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>amount of values to predict.</dd>
<dt>fig_size ((int, int)): size of a plot.</dt>
<dt>datePlot ("date", "time"): format of date. Date example : 09.01.2024, time example: 21:10</dt>
<dt><strong><code>dateStep</code></strong> :&ensp;<code>int</code></dt>
<dd>prints each n date. </dd>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>dimensions of time series. Multivariate time series not fully supported.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(DataFrame) : predictions and actuals DataFrame.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def model_forecast(model, dataset, n = 1, plot = True, fig_size = (15, 5), datePlot = &#34;date&#34;, dateStep = 1, n_features = 1):
    &#34;&#34;&#34;
    Out-of-sample forecast of a fitted model, based on a given dataset.
    Plots Predictions, Actuals (with data, if index is datetime64).

    Args:
        model (obj): model used for predictions.
        dataset (DataFrame, ndarray): time series dataset.
        n (int): amount of values to predict.
        fig_size ((int, int)): size of a plot.
        datePlot (&#34;date&#34;, &#34;time&#34;): format of date. Date example : 09.01.2024, time example: 21:10
        dateStep (int): prints each n date. 
        n_features (int): dimensions of time series. Multivariate time series not fully supported.
    Returns:
        (DataFrame) : predictions and actuals DataFrame.
    &#34;&#34;&#34;   
    if isinstance(dataset, str):
        dataset = ts_from_csv(dataset)

    # Create date indices for predictions
    if isinstance(dataset, pd.DataFrame) and dataset.index.inferred_type == &#39;datetime64&#39;:
        if dataset.index.inferred_type == &#39;datetime64&#39;:
            last_date = dataset.index[-1]
            delta = last_date - dataset.index[-2]
            if delta.days &gt;= 28 and delta.days &lt;=31:
                delta = pd.DateOffset(months=1)
            offset = pd.tseries.frequencies.to_offset(delta)
            dateIndex = pd.date_range(last_date + delta, last_date + delta*n, freq=offset)

    dataset = np.array(dataset)
    scaler = MinMaxScaler(feature_range=(-1, 1))
    dataset = scaler.fit_transform(dataset)
    dataset = dataset.tolist()
    s = get_seasonality(model)
    if isinstance(model, ARIMA) or isinstance(model, ARIMAResultsWrapper)  or isinstance(model, ARIMAResults): 
        model = ARIMA(scaler.inverse_transform(dataset), 
                    order = get_arima_model_order(model), 
                    seasonal_order = get_arima_model_seasonal_order(model))
        model = model.fit()
        predictions = model.forecast(n).reshape((-1, 1))
    else:
    # Generate n predictions, use last look_back values
        X = dataset[-s:]
        predictions = []
        for i in range(n):
            fromX = s - i
            a = X[-fromX:] if fromX &gt; 0 else []
            fromPredictions = min(i,s)
            a = a + predictions[-fromPredictions:]
            a = np.array(a).reshape(1, -1, n_features)
            prediction = model.predict(a, verbose = 0).tolist()
            predictions = predictions + prediction

        predictions = scaler.inverse_transform(predictions)
    
    df = pd.DataFrame({&#39;predictions&#39;: predictions.flatten()}, index = dateIndex)
    if plot:
        # Get indices for plotting
        if datePlot == &#34;date&#34;:
            date = [str(d)[:10] for d in df.index.values]
        elif datePlot == &#34;time&#34;: 
            date = [str(d)[11:16] for d in df.index.values]
        
        x = date
        y = df[&#34;predictions&#34;].values.tolist()

        # plot predictions
        plt.figure(figsize=fig_size)
        plt.plot(x,y)
        plt.xticks(rotation = 75)
        plt.xticks(np.arange(0, len(x)+1, dateStep))
        plt.show()

    return df</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.plot_acf"><code class="name flex">
<span>def <span class="ident">plot_acf</span></span>(<span>dataset_path, lags=12, column=1, index=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Take path of dataset and plot a decompose on trend and seasonality</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to .csv file.</dd>
<dt><strong><code>lags</code></strong> :&ensp;<code>int</code></dt>
<dd>amount of lags to plot.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>int, str, iterable</code></dt>
<dd>column index or name of time series values. Multivariate time series not fully supported yet.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int, str</code></dt>
<dd>column index or name of time series timestamps.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_acf(dataset_path, lags = 12, column = 1, index = 0):
    &#34;&#34;&#34;
    Take path of dataset and plot a decompose on trend and seasonality
    
    Args:
        dataset_path (str): path to .csv file.
        lags (int): amount of lags to plot.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
    &#34;&#34;&#34;
    dataset = pd.read_csv(dataset_path, parse_dates=True, index_col=index, usecols = [index, column])
    dataset = dataset.interpolate()
    statsmodel_plot_acf(dataset, lags = lags)</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.plot_decompose"><code class="name flex">
<span>def <span class="ident">plot_decompose</span></span>(<span>dataset_path, period=None, column=1, index=0, max_plot=10000, model='additive', method='stl', seasonal=7, trend=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Take path of dataset and plot a decompose on trend and seasonality</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to .csv file.</dd>
<dt><strong><code>period</code></strong> :&ensp;<code>int, None</code></dt>
<dd>period of the series.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>int, str, iterable</code></dt>
<dd>column index or name of time series values. Multivariate time series not fully supported yet.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int, str</code></dt>
<dd>column index or name of time series timestamps.</dd>
<dt>max_plot(int): maximum number of values to plot.</dt>
<dt>model ("additive", "multiplicative"): seasonal decompose model.</dt>
<dt>method ("stl", "ma", "naive", "seasonal_decompose"): method of decomposition. "ma" and "naive" refer to seasonal_decompose</dt>
<dt><strong><code>seasonal</code></strong> :&ensp;<code>int</code></dt>
<dd>required for Seasonal ARIMA. Seasonality of time series.</dd>
<dt><strong><code>trend</code></strong> :&ensp;<code>int, None</code></dt>
<dd>length of the trend smoother.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_decompose(dataset_path, period = None, column = 1, index = 0, max_plot = 10000, model = &#34;additive&#34;, method = &#34;stl&#34;, seasonal = 7, trend = None):
    &#34;&#34;&#34;
    Take path of dataset and plot a decompose on trend and seasonality
    
    Args:
        dataset_path (str): path to .csv file.
        period (int, None): period of the series.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
        max_plot(int): maximum number of values to plot.
        model (&#34;additive&#34;, &#34;multiplicative&#34;): seasonal decompose model.
        method (&#34;stl&#34;, &#34;ma&#34;, &#34;naive&#34;, &#34;seasonal_decompose&#34;): method of decomposition. &#34;ma&#34; and &#34;naive&#34; refer to seasonal_decompose
        seasonal (int): required for Seasonal ARIMA. Seasonality of time series.
        trend (int, None): length of the trend smoother.
    &#34;&#34;&#34;
    dataset = pd.read_csv(dataset_path, parse_dates=True, index_col=index, usecols = [index, column])
    dataset = dataset.interpolate()
    if method.lower() == &#34;stl&#34;:
        result = STL(dataset[-max_plot:].squeeze(), period = period, seasonal = seasonal, trend = trend).fit()
    elif method is None or method.lower() == &#34;ma&#34; or method.lower() == &#34;naive&#34; or method.lower() == &#34;seasonal_decompose&#34;:
        result = seasonal_decompose(dataset[-max_plot:], model=model, period=period)
    else:
        raise Exception(&#34;method cant be identified&#34;)
    
    result.plot()
    plt.show()</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.predict_array"><code class="name flex">
<span>def <span class="ident">predict_array</span></span>(<span>model, dataset, look_back, scaler=None, plot=True, get='mape', print_values=True, verbose=True, fig_size=(15, 5))</span>
</code></dt>
<dd>
<div class="desc"><p>Show fitted model predictions on a given data</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>obj</code></dt>
<dd>model used for predictions.</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>DataFrame, ndarray</code></dt>
<dd>time series dataset.</dd>
<dt><strong><code>look_back</code></strong> :&ensp;<code>int</code></dt>
<dd>amount of values in a single X.</dd>
<dt><strong><code>scaler</code></strong> :&ensp;<code>obj</code></dt>
<dd>scaler object.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>plot predictions.</dd>
<dt><strong><code>get</code></strong> :&ensp;<code>str</code></dt>
<dd>error metric to return. Supports rmse, mse, mae, mape, all.</dd>
<dt><strong><code>print_values</code></strong> :&ensp;<code>bool</code></dt>
<dd>prints predictions and actuals DataFrame.</dd>
</dl>
<p>verbose(int): print additional information.
fig_size ((int, int)): size of a plot.</p>
<h2 id="returns">Returns</h2>
<p>(float, dict of floats) : error metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_array(model, 
                  dataset, 
                  look_back, 
                  scaler = None, 
                  plot = True, 
                  get = &#34;mape&#34;, 
                  print_values = True, 
                  verbose = True, 
                  fig_size = (15, 5)):
    &#34;&#34;&#34;
    Show fitted model predictions on a given data
    
    Args:
        model (obj): model used for predictions.
        dataset (DataFrame, ndarray): time series dataset.
        look_back (int): amount of values in a single X.
        scaler (obj): scaler object.
        plot (bool): plot predictions.
        get (str): error metric to return. Supports rmse, mse, mae, mape, all.
        print_values (bool): prints predictions and actuals DataFrame.
        verbose(int): print additional information.
        fig_size ((int, int)): size of a plot.
    Returns:
        (float, dict of floats) : error metric.
    &#34;&#34;&#34;
    # if look_back is None:
    #     print(&#34;Look_back not set, setting to 12...&#34;)
    #     look_back = 12

    if scaler is None:
        scaler = MinMaxScaler(feature_range=(-1, 1))
        data = Scaler.fit_transform(dataset)

    # extract X and y values from data
    data_x, data_y = create_dataset(data, look_back)
    x_stf = np.reshape(data_x, (data_x.shape[0], data_x.shape[1], 1))

    return eval_model(model, 
                    x_stf, 
                    data_y, 
                    scaler, 
                    max_plot = 100, 
                    plot = plot, 
                    get = get, 
                    print_values = print_values, 
                    verbose = verbose, 
                    fig_size = fig_size)</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.prepare_dataset"><code class="name flex">
<span>def <span class="ident">prepare_dataset</span></span>(<span>dataset, train_size=None, test_size=None, look_back=12, val_size=None, n_features=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Split dataset on training, validation and testing arrays, scale data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>DataFrame, ndarray</code></dt>
<dd>time series dataset.</dd>
<dt><strong><code>train_size</code></strong> :&ensp;<code>float</code></dt>
<dd>Value from 0 to 1 to specify fraction of train dataset. Default value : 0.9.</dd>
<dt><strong><code>test_size</code></strong> :&ensp;<code>float</code></dt>
<dd>Value from 0 to 1 to specify fraction of test dataset. Not needed if train_size is specified. Default value : 1 - train_size</dd>
<dt><strong><code>look_back</code></strong> :&ensp;<code>int</code></dt>
<dd>amount of values in a single X.</dd>
<dt><strong><code>val_size</code></strong> :&ensp;<code>float</code></dt>
<dd>Value from 0 to 1 to specify fraction of val dataset inside of a train dataset. Default value : 0.1.</dd>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>dimensions of time series. Multivariate time series not fully supported.</dd>
</dl>
<p>Returns:train_x_stf, train_y, val_x_stf, val_y, test_x_stf, test_y, trainScaler, valScaler, testScaler
(ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, obj, obj, obj) : train X, train y, val X, val y, test X, test y, trainScaler object, valScaler object, testScaler object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_dataset(dataset, train_size = None, test_size = None, look_back = 12, val_size = None, n_features = 1):
    &#34;&#34;&#34;
    Split dataset on training, validation and testing arrays, scale data.
    
    Args:
        dataset (DataFrame, ndarray): time series dataset.
        train_size (float): Value from 0 to 1 to specify fraction of train dataset. Default value : 0.9.
        test_size (float): Value from 0 to 1 to specify fraction of test dataset. Not needed if train_size is specified. Default value : 1 - train_size
        look_back (int): amount of values in a single X.
        val_size (float): Value from 0 to 1 to specify fraction of val dataset inside of a train dataset. Default value : 0.1.
        n_features (int): dimensions of time series. Multivariate time series not fully supported.
        
    Returns:train_x_stf, train_y, val_x_stf, val_y, test_x_stf, test_y, trainScaler, valScaler, testScaler
        (ndarray, ndarray, ndarray, ndarray, ndarray, ndarray, obj, obj, obj) : train X, train y, val X, val y, test X, test y, trainScaler object, valScaler object, testScaler object.
    &#34;&#34;&#34;
    if not(isinstance(dataset, np.ndarray)):
        dataset = dataset.values
        dataset = dataset.astype(&#39;float64&#39;)

    if (np.isnan(dataset).any()):
        dataset = interpolate_nan(dataset)

    if train_size is None: 
        if test_size is None:
            train_size = 0.9
        elif test_size &lt; 1:
            train_size = 1 - test_size
        else:
            train_size = test_size/len(dataset)

    if val_size is None:
        val_size = (train_size)/10
    else:
        val_size = (train_size * val_size)

    # split into train and test sets
    train_size = train_size - val_size
    train_num = int(len(dataset) * train_size)
    val_num = train_num + int(len(dataset) * val_size)
    train, val, test = dataset[:train_num, :], dataset[train_num:val_num, :], dataset[val_num:, :]

    # normalize dataset separately
    trainScaler = MinMaxScaler(feature_range=(-1, 1))
    train = trainScaler.fit_transform(train)

    valScaler = MinMaxScaler(feature_range=(-1, 1))
    val = valScaler.fit_transform(val)

    testScaler = MinMaxScaler(feature_range=(-1, 1))
    test = testScaler.fit_transform(test)   

    # reshape into X=t and Y=t+1
    scaled_dataset = np.array(train.tolist() + val.tolist() + test.tolist())
    scaled_x, scaled_y = create_dataset(scaled_dataset, look_back)
    train_x = scaled_x[:train_num - look_back]
    train_y = scaled_y[:train_num - look_back]
    val_x = scaled_x[train_num - look_back:val_num - look_back]
    val_y = scaled_y[train_num - look_back:val_num - look_back]
    test_x = scaled_x[val_num - look_back:]
    test_y = scaled_y[val_num - look_back:]

    # reshape input to be [samples, time steps, features]
    train_x_stf = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], n_features))
    test_x_stf = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], n_features))
    val_x_stf = np.reshape(val_x, (val_x.shape[0], val_x.shape[1], n_features))

    return train_x_stf, train_y, val_x_stf, val_y, test_x_stf, test_y, trainScaler, valScaler, testScaler</code></pre>
</details>
</dd>
<dt id="TSEnsemble.utils.ts_from_csv"><code class="name flex">
<span>def <span class="ident">ts_from_csv</span></span>(<span>dataset_path, column=1, index=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts .csv file to pandas DataFrame, dropping all columns besides index and column.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to .csv file.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>int, str, iterable</code></dt>
<dd>column index or name of time series values. Multivariate time series not fully supported yet.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int, str</code></dt>
<dd>column index or name of time series timestamps.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>DataFrame.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ts_from_csv(dataset_path, column = 1, index = 0):
    &#34;&#34;&#34;
    Converts .csv file to pandas DataFrame, dropping all columns besides index and column.
    Args:
        dataset_path (str): path to .csv file.
        column (int, str, iterable): column index or name of time series values. Multivariate time series not fully supported yet.
        index (int, str): column index or name of time series timestamps.
    Returns:
        DataFrame.
    &#34;&#34;&#34;
    if isinstance(column, int) or isinstance(column, str):
        df = pd.read_csv(dataset_path, parse_dates = True, index_col = index, usecols = [index, column])
    else:
        df = pd.read_csv(dataset_path, parse_dates = True, index_col = index, usecols = [index, *column])
    df.astype(float)
    df = df.interpolate()
    return df</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TSEnsemble" href="index.html">TSEnsemble</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="TSEnsemble.utils.create_dataset" href="#TSEnsemble.utils.create_dataset">create_dataset</a></code></li>
<li><code><a title="TSEnsemble.utils.eval_model" href="#TSEnsemble.utils.eval_model">eval_model</a></code></li>
<li><code><a title="TSEnsemble.utils.get_arima_model_S" href="#TSEnsemble.utils.get_arima_model_S">get_arima_model_S</a></code></li>
<li><code><a title="TSEnsemble.utils.get_arima_model_order" href="#TSEnsemble.utils.get_arima_model_order">get_arima_model_order</a></code></li>
<li><code><a title="TSEnsemble.utils.get_arima_model_seasonal_order" href="#TSEnsemble.utils.get_arima_model_seasonal_order">get_arima_model_seasonal_order</a></code></li>
<li><code><a title="TSEnsemble.utils.get_coeff_determination" href="#TSEnsemble.utils.get_coeff_determination">get_coeff_determination</a></code></li>
<li><code><a title="TSEnsemble.utils.get_mae" href="#TSEnsemble.utils.get_mae">get_mae</a></code></li>
<li><code><a title="TSEnsemble.utils.get_mape" href="#TSEnsemble.utils.get_mape">get_mape</a></code></li>
<li><code><a title="TSEnsemble.utils.get_mse" href="#TSEnsemble.utils.get_mse">get_mse</a></code></li>
<li><code><a title="TSEnsemble.utils.get_rmse" href="#TSEnsemble.utils.get_rmse">get_rmse</a></code></li>
<li><code><a title="TSEnsemble.utils.get_seasonality" href="#TSEnsemble.utils.get_seasonality">get_seasonality</a></code></li>
<li><code><a title="TSEnsemble.utils.interpolate_nan" href="#TSEnsemble.utils.interpolate_nan">interpolate_nan</a></code></li>
<li><code><a title="TSEnsemble.utils.isStationary" href="#TSEnsemble.utils.isStationary">isStationary</a></code></li>
<li><code><a title="TSEnsemble.utils.isStationaryArray" href="#TSEnsemble.utils.isStationaryArray">isStationaryArray</a></code></li>
<li><code><a title="TSEnsemble.utils.model_forecast" href="#TSEnsemble.utils.model_forecast">model_forecast</a></code></li>
<li><code><a title="TSEnsemble.utils.plot_acf" href="#TSEnsemble.utils.plot_acf">plot_acf</a></code></li>
<li><code><a title="TSEnsemble.utils.plot_decompose" href="#TSEnsemble.utils.plot_decompose">plot_decompose</a></code></li>
<li><code><a title="TSEnsemble.utils.predict_array" href="#TSEnsemble.utils.predict_array">predict_array</a></code></li>
<li><code><a title="TSEnsemble.utils.prepare_dataset" href="#TSEnsemble.utils.prepare_dataset">prepare_dataset</a></code></li>
<li><code><a title="TSEnsemble.utils.ts_from_csv" href="#TSEnsemble.utils.ts_from_csv">ts_from_csv</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>